import os
import time
import json
import tempfile
import logging
import subprocess
import smtplib
from email.mime.text import MIMEText
import asyncio
import librosa
import soundfile as sf
from fastapi import FastAPI
import boto3
import torch
from pyannote.audio import Pipeline
import whisper  # ‚Üê –î–û–ë–ê–í–ò–¢–¨ –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç

# ------------------- –ö–æ–Ω—Ñ–∏–≥–∏ -------------------
S3_BUCKET = "diarization-files"
LOCAL_TMP = os.path.join(os.getcwd(), "tmp", "audiot")
CHECK_INTERVAL = 10
SUPPORTED_EXT = ['mp3', 'm4a', 'wav', 'flac']

EMAIL_HOST = "smtp.mailmug.net"
EMAIL_PORT = 2525
EMAIL_USER = "rv52j9uijrxg83fv"
EMAIL_PASS = "i2qukytuj2hrtunr"
EMAIL_TO = "your-email@gmail.com"

MODELS_DIR = "./models"
PYANNOTE_MODEL = "pyannote/speaker-diarization-3.1"
WHISPER_MODEL = "large-v2"  # ‚Üê –ò–°–ü–û–õ–¨–ó–£–ï–ú large-v2 (–±—ã—Å—Ç—Ä–µ–µ —á–µ–º v3)

torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

os.makedirs(LOCAL_TMP, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)

# ------------------- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ -------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")

# ------------------- S3 -------------------
s3 = boto3.client(
    "s3",
    endpoint_url='http://127.0.0.1:9000',
    aws_access_key_id='minioadmin',
    aws_secret_access_key='minioadmin'
)

# ------------------- FastAPI -------------------
app = FastAPI()

# ------------------- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ -------------------
class PerformanceOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    @staticmethod
    def get_available_device():
        """–û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–µ–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ"""
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            if gpu_memory >= 4:
                logging.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f} GB)")
                return "cuda"
        
        logging.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU")
        return "cpu"
    
    @staticmethod
    def optimize_torch():
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º PyTorch –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏"""
        torch.set_num_threads(min(8, os.cpu_count() or 8))  # ‚Üë —É–≤–µ–ª–∏—á–∏–ª–∏ –ø–æ—Ç–æ–∫–∏
        if torch.cuda.is_available():
            torch.backends.cudnn.benchmark = True
            # –û—á–∏—â–∞–µ–º –∫–µ—à CUDA –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–µ–∫ –ø–∞–º—è—Ç–∏
            torch.cuda.empty_cache()
    
    @staticmethod
    def log_processing_time(start_time, operation_name):
        """–õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏"""
        elapsed = time.time() - start_time
        logging.info(f"‚è± {operation_name}: {elapsed:.1f} —Å–µ–∫")

# ------------------- –ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è -------------------
def convert_to_wav_fast(input_path):
    """–ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ"""
    logging.info(f"‚ö° –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º {os.path.basename(input_path)}...")
    start_time = time.time()
    
    temp_path = input_path.rsplit('.', 1)[0] + "_fast.wav"
    
    try:
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã FFmpeg
        cmd = [
            "ffmpeg", "-y", 
            "-i", input_path,
            "-ar", "16000",
            "-ac", "1",
            "-acodec", "pcm_s16le",
            "-threads", "4",  # ‚Üë –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å
            "-hide_banner",
            "-loglevel", "error",
            temp_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        os.replace(temp_path, input_path)
        PerformanceOptimizer.log_processing_time(start_time, "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è")
        return input_path
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
        if os.path.exists(temp_path):
            os.remove(temp_path)
        raise

# ------------------- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π -------------------
def load_pyannote_fast():
    """–ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ pyannote —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
    logging.info("‚ö° –ó–∞–≥—Ä—É–∂–∞–µ–º pyannote...")
    start_time = time.time()
    
    try:
        hf_token = "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"  # ‚Üê –ù–£–ñ–ï–ù –¢–û–ö–ï–ù!
        pipeline = Pipeline.from_pretrained(
            PYANNOTE_MODEL,
            use_auth_token=hf_token,
            cache_dir=MODELS_DIR
        )
        
        device_type = PerformanceOptimizer.get_available_device()
        pipeline = pipeline.to(torch.device(device_type))
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        pipeline._segmentation.batch_size = 4  # ‚Üë –±–∞—Ç—á-—Å–∞–π–∑
        pipeline._segmentation.device = torch.device(device_type)
        
        PerformanceOptimizer.log_processing_time(start_time, "–ó–∞–≥—Ä—É–∑–∫–∞ PyAnnote")
        return pipeline
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ pyannote: {e}")
        raise

def load_whisper_fast():
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ Whisper"""
    logging.info("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Whisper...")
    start_time = time.time()
    
    try:
        device_type = PerformanceOptimizer.get_available_device()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
        model = whisper.load_model(
            WHISPER_MODEL, 
            device=device_type,
            download_root=MODELS_DIR
        )
        
        PerformanceOptimizer.log_processing_time(start_time, "–ó–∞–≥—Ä—É–∑–∫–∞ Whisper")
        return model, device_type
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Whisper: {e}")
        raise

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–µ–π
diarization_pipeline = None
whisper_model = None
device = None

def initialize_models_fast():
    """–ë—ã—Å—Ç—Ä–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"""
    global diarization_pipeline, whisper_model, device
    
    if diarization_pipeline is None or whisper_model is None:
        preload_all_models()

def preload_all_models():
    """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
    logging.info("üîÑ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π...")
    global diarization_pipeline, whisper_model, device
    
    PerformanceOptimizer.optimize_torch()
    device_type = PerformanceOptimizer.get_available_device()
    
    diarization_pipeline = load_pyannote_fast()
    whisper_model, device = load_whisper_fast()
    
    logging.info("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω—ã")

# ------------------- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è -------------------
def transcribe_optimized(audio_path):
    """–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –ª—É—á—à–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
    logging.info("üéß –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è...")
    start_time = time.time()

    try:
        # –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –°–ö–û–†–û–°–¢–ò
        result = whisper_model.transcribe(
            audio_path,
            language="ru",
            fp16=True,  # –í–ö–õ–Æ–ß–ê–ï–ú FP16 (2x —É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ GPU)
            beam_size=3,  # ‚Üì —É–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            best_of=2,    # ‚Üì —É–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏  
            temperature=0.0,  # –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            no_speech_threshold=0.6,  # –õ—É—á—à–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ—á—å
            compression_ratio_threshold=2.4,  # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —à—É–º–∞
            condition_on_previous_text=False,  # ‚Üë —É—Å–∫–æ—Ä—è–µ—Ç –¥–ª–∏–Ω–Ω—ã–µ –∞—É–¥–∏–æ
            word_timestamps=True  # –ù—É–∂–Ω–æ –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
        )
        
        result_text = ""
        result_chunks = []

        for segment in result["segments"]:
            result_text += segment["text"] + " "
            result_chunks.append({
                "timestamp": [segment["start"], segment["end"]],
                "text": segment["text"].strip()
            })

        PerformanceOptimizer.log_processing_time(start_time, "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è")
        logging.info(f"üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–æ: {len(result_text)} —Å–∏–º–≤–æ–ª–æ–≤, {len(result_chunks)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        return result_text.strip(), result_chunks

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
        raise

# ------------------- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ -------------------
def process_audio_optimized(audio_path):
    """–£–ù–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–ê–Ø –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
    logging.info("üîπ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ...")
    start_time = time.time()
    
    if diarization_pipeline is None:
        raise ValueError("Diarization pipeline –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # –û—á–∏—â–∞–µ–º –∫–µ—à CUDA –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    import threading
    
    diarization_result = [None]
    transcription_result = [None]
    
    def run_diarization():
        diarization_result[0] = diarization_pipeline(audio_path)
    
    def run_transcription():
        transcription_result[0] = transcribe_optimized(audio_path)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö
    t1 = threading.Thread(target=run_diarization)
    t2 = threading.Thread(target=run_transcription)
    
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    
    full_text, chunks = transcription_result[0]
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    result = align_diarization_and_transcript_fast(diarization_result[0], chunks)
    
    PerformanceOptimizer.log_processing_time(start_time, "–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞")
    return result

def align_diarization_and_transcript_fast(diarization, transcript_chunks):
    """–ë—ã—Å—Ç—Ä–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    segments = []

    for chunk in transcript_chunks:
        start = chunk["timestamp"][0] or 0
        end = chunk["timestamp"][1] or 0
        if start == 0 and end == 0:
            continue

        best_speaker = "unknown"
        max_overlap = 0

        for turn, _, speaker in diarization.itertracks(yield_label=True):
            overlap_start = max(start, turn.start)
            overlap_end = min(end, turn.end)
            overlap_duration = max(0, overlap_end - overlap_start)

            if overlap_duration > max_overlap:
                max_overlap = overlap_duration
                best_speaker = speaker

        segments.append({
            "start": float(start),
            "end": float(end),
            "speaker": best_speaker,
            "text": chunk["text"].strip()
        })

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    merged = []
    for seg in segments:
        if (merged and 
            seg["speaker"] == merged[-1]["speaker"] and 
            seg["start"] <= merged[-1]["end"] + 1.5):  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
            merged[-1]["end"] = seg["end"]
            merged[-1]["text"] += " " + seg["text"]
        else:
            merged.append(seg)

    logging.info(f"üéØ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ –≤ {len(merged)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
    return merged

def send_email(subject, body):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ email"""
    try:
        msg = MIMEText(body)
        msg['Subject'] = subject
        msg['From'] = "test@test.tu"
        msg['To'] = EMAIL_TO
        with smtplib.SMTP(EMAIL_HOST, EMAIL_PORT) as server:
            server.login(EMAIL_USER, EMAIL_PASS)
            server.send_message(msg)
        logging.info(f"üìß Email –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {subject}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ email: {e}")

def process_file_fast(s3_key):
    """–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞"""
    local_path = None
    total_start_time = time.time()
    
    try:
        initialize_models_fast()

        local_path = os.path.join(LOCAL_TMP, os.path.basename(s3_key))
        logging.info(f"‚¨áÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª S3: {s3_key}")
        s3.download_file(S3_BUCKET, s3_key, local_path)

        file_size_mb = os.path.getsize(local_path) / (1024 * 1024)
        logging.info(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size_mb:.1f} MB")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        ext = local_path.rsplit('.', 1)[1].lower()
        if ext != "wav":
            local_path = convert_to_wav_fast(local_path)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        duration = librosa.get_duration(filename=local_path)
        logging.info(f"‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ: {duration:.1f} —Å–µ–∫—É–Ω–¥")

        # –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        result_segments = process_audio_optimized(local_path)

        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        result_json = json.dumps({
            "status": "success",
            "segments": result_segments,
            "total_duration": duration,
            "file": os.path.basename(s3_key),
            "processing_time": round(time.time() - total_start_time, 1)
        }, ensure_ascii=False, indent=2)

        send_email(f"–î–∏–∞—Ä–∏–∑–∞—Ü–∏—è {os.path.basename(s3_key)}", result_json)
        
        try:
            s3.delete_object(Bucket=S3_BUCKET, Key=s3_key)
            logging.info(f"üóë –£–¥–∞–ª–µ–Ω –∏–∑ S3: {s3_key}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ S3: {e}")
        
        total_time = time.time() - total_start_time
        speed_ratio = duration / total_time if total_time > 0 else 0
        logging.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.1f} —Å–µ–∫ ({speed_ratio:.2f}x —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)")

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {s3_key}: {e}")
        send_email(f"–û—à–∏–±–∫–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ {os.path.basename(s3_key)}", str(e))
    finally:
        if local_path and os.path.exists(local_path):
            os.remove(local_path)
        # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

# ------------------- –§–æ–Ω–æ–≤—ã–π —Ü–∏–∫–ª -------------------
async def background_loop():
    """–§–æ–Ω–æ–≤—ã–π —Ü–∏–∫–ª"""
    while True:
        try:
            response = s3.list_objects_v2(Bucket=S3_BUCKET)
            objs = response.get("Contents", [])

            if objs:
                logging.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(objs)}")

            for obj in objs:
                process_file_fast(obj["Key"])
                await asyncio.sleep(1)

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ü–∏–∫–ª–µ: {e}")
            await asyncio.sleep(30)

        await asyncio.sleep(CHECK_INTERVAL)

@app.on_event("startup")
async def startup_event():
    """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    logging.info("üöÄ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
    preload_all_models()
    logging.info("üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–æ–Ω–æ–≤–æ–≥–æ —Ü–∏–∫–ª–∞...")
    asyncio.create_task(background_loop())

@app.get("/")
def read_root():
    return {"status": "ok", "optimized": True, "version": "2.0"}

@app.get("/health")
def health_check():
    device_type = PerformanceOptimizer.get_available_device()
    return {
        "status": "healthy",
        "device": device_type,
        "models_loaded": diarization_pipeline is not None and whisper_model is not None
    }

if __name__ == "__main__":
    asyncio.run(background_loop())
import os
import time
import json
import tempfile
import logging
import subprocess
import smtplib
from email.mime.text import MIMEText
import asyncio
import gc
import librosa
import soundfile as sf
from fastapi import FastAPI
import boto3
import torch
import torchaudio

import numpy as np
from pyannote.audio import Pipeline
from transformers import (
    WhisperProcessor,
    WhisperForConditionalGeneration,
    pipeline as hf_pipeline
)
from huggingface_hub import snapshot_download

# ------------------- –ö–æ–Ω—Ñ–∏–≥–∏ -------------------
S3_BUCKET = "diarization-files"
LOCAL_TMP = "/tmp/audiot"
CHECK_INTERVAL = 10
SUPPORTED_EXT = ['mp3', 'm4a', 'wav', 'flac']

EMAIL_HOST = "smtp.mailmug.net"
EMAIL_PORT = 2525
EMAIL_USER = "rv52j9uijrxg83fv"
EMAIL_PASS = "i2qukytuj2hrtunr"
EMAIL_TO = "your-email@gmail.com"

MODELS_DIR = "./models"
PYANNOTE_MODEL = "pyannote/speaker-diarization-3.1"
WHISPER_MODEL = "openai/whisper-large-v3-turbo"  # –í–µ—Ä–Ω—É–ª–∏ small –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏

os.makedirs(LOCAL_TMP, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)

# ------------------- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ -------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")

# ------------------- S3 -------------------
s3 = boto3.client(
    "s3",
    # endpoint_url='http://minio:9000',
    endpoint_url='http://127.0.0.1:9000',
    aws_access_key_id='minioadmin',
    aws_secret_access_key='minioadmin'
)

# ------------------- FastAPI -------------------
app = FastAPI()

# ------------------- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ -------------------
class PerformanceOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    @staticmethod
    def get_available_device():
        """–û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–µ–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ"""
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            if gpu_memory >= 4:  # –ï—Å–ª–∏ GPU —Å 4+ GB –ø–∞–º—è—Ç–∏
                logging.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f} GB)")
                return "cuda"
        
        if hasattr(torch, 'mps') and torch.backends.mps.is_available():
            logging.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º Apple MPS")
            return "mps"
        
        logging.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU")
        return "cpu"
    
    @staticmethod
    def optimize_torch():
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º PyTorch –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏"""
        torch.set_num_threads(min(4, os.cpu_count() or 4))
        if torch.cuda.is_available():
            torch.backends.cudnn.benchmark = True
    
    @staticmethod
    def log_processing_time(start_time, operation_name):
        """–õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏"""
        elapsed = time.time() - start_time
        logging.info(f"‚è± {operation_name}: {elapsed:.1f} —Å–µ–∫")

# ------------------- –ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è -------------------
def convert_to_wav_fast(input_path):
    """–ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ"""
    logging.info(f"‚ö° –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º {os.path.basename(input_path)}...")
    start_time = time.time()
    
    temp_path = input_path.rsplit('.', 1)[0] + "_fast.wav"
    
    try:
        # –ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        cmd = [
            "ffmpeg", "-y", 
            "-i", input_path,
            "-ar", "16000",
            "-ac", "1",
            "-acodec", "pcm_s16le",
            "-f", "wav",
            "-threads", "2",  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            temp_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode != 0:
            raise subprocess.CalledProcessError(result.returncode, cmd, result.stdout, result.stderr)
        
        os.replace(temp_path, input_path)
        PerformanceOptimizer.log_processing_time(start_time, "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è")
        return input_path
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
        if os.path.exists(temp_path):
            os.remove(temp_path)
        raise

# ------------------- –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π -------------------
def load_pyannote_fast():
    """–ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ pyannote"""
    logging.info("‚ö° –ó–∞–≥—Ä—É–∂–∞–µ–º pyannote...")
    start_time = time.time()
    
    try:
        hf_token = os.getenv("HF_TOKEN")
        pipeline = Pipeline.from_pretrained(
            PYANNOTE_MODEL,
            use_auth_token=hf_token,
            cache_dir=MODELS_DIR
        )
        
        device = PerformanceOptimizer.get_available_device()
        pipeline = pipeline.to(torch.device(device))
        
        PerformanceOptimizer.log_processing_time(start_time, "–ó–∞–≥—Ä—É–∑–∫–∞ PyAnnote")
        return pipeline
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ pyannote: {e}")
        raise

def load_whisper_fast():
    """–ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ Whisper"""
    logging.info("‚ö° –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper...")
    start_time = time.time()
    
    try:
        local_path = os.path.join(MODELS_DIR, "whisper-trubo")
        
        if not os.path.exists(local_path):
            logging.info("üì• –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å...")
            local_path = snapshot_download(repo_id=WHISPER_MODEL, cache_dir=MODELS_DIR)

        processor = WhisperProcessor.from_pretrained(local_path)
        model = WhisperForConditionalGeneration.from_pretrained(local_path)
        
        device = PerformanceOptimizer.get_available_device()
        model.to(device)
        model.eval()
        
        PerformanceOptimizer.log_processing_time(start_time, "–ó–∞–≥—Ä—É–∑–∫–∞ Whisper")
        return processor, model, device
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Whisper: {e}")
        raise

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–µ–π
diarization_pipeline = None
processor = None
whisper_model = None
device = None

def initialize_models_fast():
    """–ë—ã—Å—Ç—Ä–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"""
    global diarization_pipeline, processor, whisper_model, device
    
    PerformanceOptimizer.optimize_torch()
    
    if diarization_pipeline is None:
        diarization_pipeline = load_pyannote_fast()
        
    if whisper_model is None:
        processor, whisper_model, device = load_whisper_fast()
    
    logging.info("‚úÖ –ú–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞–±–æ—Ç–µ")

# ------------------- –ë—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è -------------------
def transcribe_fast(audio_path):
    """–ë—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è"""
    logging.info("üéß –ë—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è...")
    start_time = time.time()
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        asr = hf_pipeline(
            "automatic-speech-recognition",
            model=WHISPER_MODEL,
            chunk_length_s=20,
            stride_length_s=5,
            generate_kwargs={"language": "russian"},
            device=0 if torch.cuda.is_available() else -1,  # GPU –µ—Å–ª–∏ –µ—Å—Ç—å
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        )

        result = asr(audio_path, return_timestamps=True)
        
        PerformanceOptimizer.log_processing_time(start_time, "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è")
        return result["text"], result["chunks"]

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
        raise

# ------------------- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ -------------------
def process_short_audio_fast(audio_path):
    """–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞—É–¥–∏–æ"""
    logging.info("üîπ –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ...")
    start_time = time.time()
    
    if diarization_pipeline is None:
        raise ValueError("Diarization pipeline –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è
    diarization = diarization_pipeline(audio_path)
    
    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
    full_text, chunks = transcribe_fast(audio_path)
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
    result = align_diarization_and_transcript_fast(diarization, chunks)
    
    PerformanceOptimizer.log_processing_time(start_time, "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ")
    return result

def process_long_audio_fast(audio_path, chunk_duration=300):  # –£–≤–µ–ª–∏—á–∏–ª–∏ —á–∞–Ω–∫–∏
    """–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ"""
    logging.info("üî∏ –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ...")
    start_time = time.time()
    
    if diarization_pipeline is None:
        raise ValueError("Diarization pipeline –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∞—É–¥–∏–æ —Å—Ä–∞–∑—É (–±—ã—Å—Ç—Ä–µ–µ —á–µ–º –ø–æ —á–∞—Å—Ç—è–º)
    y, sr = librosa.load(audio_path, sr=16000, mono=True)
    total_duration = len(y) / sr
    logging.info(f"üìä –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration:.1f} —Å–µ–∫")

    all_segments = []
    chunk_size = chunk_duration * sr

    for i, start_sample in enumerate(range(0, len(y), chunk_size)):
        chunk_end = min(start_sample + chunk_size, len(y))
        chunk_audio = y[start_sample:chunk_end]

        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
            temp_path = temp_file.name
            sf.write(temp_path, chunk_audio, sr)

        try:
            logging.info(f"üîπ –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ {i+1}...")
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            chunk_diarization = diarization_pipeline(temp_path)
            _, chunk_chunks = transcribe_fast(temp_path)
            chunk_result = align_diarization_and_transcript_fast(chunk_diarization, chunk_chunks)

            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            time_offset = start_sample / sr
            for segment in chunk_result:
                segment["start"] += time_offset
                segment["end"] += time_offset

            all_segments.extend(chunk_result)
            logging.info(f"‚úÖ –ß–∞–Ω–∫ {i+1} –æ–±—Ä–∞–±–æ—Ç–∞–Ω")

        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    PerformanceOptimizer.log_processing_time(start_time, "–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ")
    return all_segments

def align_diarization_and_transcript_fast(diarization, transcript_chunks):
    """–ë—ã—Å—Ç—Ä–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    segments = []

    for chunk in transcript_chunks:
        start = chunk["timestamp"][0] or 0
        end = chunk["timestamp"][1] or 0
        if start == 0 and end == 0:
            continue

        best_speaker = "unknown"
        max_overlap = 0

        for turn, _, speaker in diarization.itertracks(yield_label=True):
            overlap_start = max(start, turn.start)
            overlap_end = min(end, turn.end)
            overlap_duration = max(0, overlap_end - overlap_start)

            if overlap_duration > max_overlap:
                max_overlap = overlap_duration
                best_speaker = speaker

        segments.append({
            "start": float(start),
            "end": float(end),
            "speaker": best_speaker,
            "text": chunk["text"].strip()
        })

    # –ë—ã—Å—Ç—Ä–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
    merged = []
    for seg in segments:
        if (merged and 
            seg["speaker"] == merged[-1]["speaker"] and 
            seg["start"] <= merged[-1]["end"] + 2.0):  # –£–≤–µ–ª–∏—á–∏–ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª
            merged[-1]["end"] = seg["end"]
            merged[-1]["text"] += " " + seg["text"]
        else:
            merged.append(seg)

    return merged

def send_email(subject, body):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ email"""
    try:
        msg = MIMEText(body)
        msg['Subject'] = subject
        msg['From'] = "test@test.tu"
        msg['To'] = EMAIL_TO
        with smtplib.SMTP(EMAIL_HOST, EMAIL_PORT) as server:
            server.login(EMAIL_USER, EMAIL_PASS)
            server.send_message(msg)
        logging.info(f"üìß Email –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {subject}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ email: {e}")

def process_file_fast(s3_key):
    """–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞"""
    local_path = None
    total_start_time = time.time()
    
    try:
        initialize_models_fast()

        local_path = os.path.join(LOCAL_TMP, os.path.basename(s3_key))
        logging.info(f"‚¨áÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª S3: {s3_key}")
        s3.download_file(S3_BUCKET, s3_key, local_path)

        file_size_mb = os.path.getsize(local_path) / (1024 * 1024)
        logging.info(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size_mb:.1f} MB")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        ext = local_path.rsplit('.', 1)[1].lower()
        if ext != "wav":
            local_path = convert_to_wav_fast(local_path)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        duration = librosa.get_duration(filename=local_path)
        logging.info(f"‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ: {duration:.1f} —Å–µ–∫—É–Ω–¥")

        # –í—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
        if duration > 600:  # 10 –º–∏–Ω—É—Ç
            result_segments = process_long_audio_fast(local_path)
        else:
            result_segments = process_short_audio_fast(local_path)

        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        result_json = json.dumps({
            "status": "success",
            "segments": result_segments,
            "total_duration": duration,
            "file": os.path.basename(s3_key),
            "processing_time": round(time.time() - total_start_time, 1)
        }, ensure_ascii=False, indent=2)

        send_email(f"–î–∏–∞—Ä–∏–∑–∞—Ü–∏—è {os.path.basename(s3_key)}", result_json)
        try:
            s3.delete_object(Bucket=S3_BUCKET, Key=s3_key)
            logging.info(f"üóë –£–¥–∞–ª–µ–Ω –∏–∑ S3: {s3_key}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ S3: {e}")
        
        total_time = time.time() - total_start_time
        logging.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.1f} —Å–µ–∫: {len(result_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {s3_key}: {e}")
        send_email(f"–û—à–∏–±–∫–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ {os.path.basename(s3_key)}", str(e))
    finally:
        if local_path and os.path.exists(local_path):
            os.remove(local_path)

# ------------------- –§–æ–Ω–æ–≤—ã–π —Ü–∏–∫–ª -------------------
async def background_loop():
    """–§–æ–Ω–æ–≤—ã–π —Ü–∏–∫–ª"""
    while True:
        try:
            response = s3.list_objects_v2(Bucket=S3_BUCKET)
            objs = response.get("Contents", [])

            if objs:
                logging.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(objs)}")

            for obj in objs:
                process_file_fast(obj["Key"])
                await asyncio.sleep(2)  # –£–º–µ–Ω—å—à–∏–ª–∏ –ø–∞—É–∑—É

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ü–∏–∫–ª–µ: {e}")
            await asyncio.sleep(30)

        await asyncio.sleep(CHECK_INTERVAL)

@app.on_event("startup")
async def startup_event():
    """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    logging.info("üöÄ –ó–∞–ø—É—Å–∫ –±—ã—Å—Ç—Ä–æ–≥–æ —Ñ–æ–Ω–æ–≤–æ–≥–æ —Ü–∏–∫–ª–∞...")
    asyncio.create_task(background_loop())

# ------------------- FastAPI endpoint -------------------
@app.get("/")
def read_root():
    return {"status": "ok", "optimized_for_speed": True}

@app.get("/health")
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    device_type = PerformanceOptimizer.get_available_device()
    return {
        "status": "healthy",
        "device": device_type,
        "models_loaded": diarization_pipeline is not None and whisper_model is not None,
        "gpu_available": torch.cuda.is_available()
    }

@app.get("/performance")
def performance_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    return {
        "device": PerformanceOptimizer.get_available_device(),
        "gpu_available": torch.cuda.is_available(),
        "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,
        "cpu_threads": torch.get_num_threads()
    }

# ------------------- –ó–∞–ø—É—Å–∫ -------------------
if __name__ == "__main__":
    asyncio.run(background_loop())